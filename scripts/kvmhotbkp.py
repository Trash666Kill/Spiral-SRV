#!/usr/bin/env python3
import libvirt
import sys
import os
import shutil
import time
import argparse
import subprocess
import signal
import re 
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
import logging

# --- CONSTANTS ---
DISK_FORMAT = 'qcow2'
CONNECT_URI = 'qemu:///system'
SAFETY_MARGIN_PERCENT = 0.10
LOG_DIR = "/var/log/virsh"
FORBIDDEN_PATTERNS = ['_snap_', '_tmp_', 'snapshot', '.bak']

# --- GLOBAL VARIABLES ---
CURRENT_DOMAIN_NAME = None
BACKUP_JOB_RUNNING = False
FILES_TO_CLEANUP = []      # Partial DESTINATION files (.bak)

# --- LOGGER ---
logger = logging.getLogger('virsh_hotbkp')
logger.setLevel(logging.DEBUG) 

def setup_logging(domain_name, timestamp):
    try:
        log_dir_final = LOG_DIR
        # Fallback to /tmp if no permission in /var/log
        if not os.access(os.path.dirname(LOG_DIR), os.W_OK) and not os.path.isdir(LOG_DIR):
            log_dir_final = "/tmp/virsh_logs"
        os.makedirs(log_dir_final, exist_ok=True)
        log_path = os.path.join(log_dir_final, f"{domain_name}-{timestamp}.log")
        
        file_handler = logging.FileHandler(log_path, encoding='utf-8')
        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
        logger.addHandler(file_handler)

        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(logging.Formatter('%(levelname)s: %(message)s'))
        logger.addHandler(console_handler)
    except Exception as e:
        print(f"LOG ERROR: {e}", file=sys.stderr); sys.exit(1)

# --- CLEANUP AND EMERGENCY ---

def perform_cleanup(exit_after=False):
    global BACKUP_JOB_RUNNING, CURRENT_DOMAIN_NAME
    
    if sys.stdout.isatty(): print() 
    logger.warning("--- CLEANUP PROTOCOL INITIATED ---")

    # 1. Abort Libvirt Job (If there is an active one created by this script)
    if BACKUP_JOB_RUNNING and CURRENT_DOMAIN_NAME:
        logger.warning("Attempting to abort active Libvirt job...")
        try: 
            subprocess.run(['virsh', 'domjobabort', CURRENT_DOMAIN_NAME], check=True, capture_output=True)
            logger.info(" -> Libvirt job aborted successfully.")
        except subprocess.CalledProcessError as e:
            logger.critical(f" -> FAILED to abort job. VM restart might be required. Error: {e.stderr}")
        BACKUP_JOB_RUNNING = False

    # 2. Clean partial .bak files (Garbage generated by failure)
    if FILES_TO_CLEANUP:
        logger.info("Cleaning up partial destination files...")
        for f in FILES_TO_CLEANUP:
            if os.path.exists(f):
                try: os.remove(f); logger.info(f" -> Deleted: {os.path.basename(f)}")
                except: pass
    
    if exit_after: logger.warning("--- INTERRUPTED ---"); sys.exit(1)

def signal_handler(sig, frame):
    perform_cleanup(exit_after=True)

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# --- UTILS ---

def get_disk_details_from_xml(dom, target_devs_list):
    logger.info(f"Reading XML for disks: {target_devs_list}")
    details = {}
    found_devs = []
    try:
        root = ET.fromstring(dom.XMLDesc(0))
        for device in root.findall('./devices/disk'):
            target = device.find('target')
            if target is not None:
                dev_name = target.get('dev')
                if dev_name in target_devs_list:
                    source = device.find('source')
                    if source is not None and source.get('file'):
                        details[dev_name] = {'path': source.get('file')}
                        found_devs.append(dev_name)
    except Exception as e: logger.error(f"XML Error: {e}"); return None
        
    missing_devs = [d for d in target_devs_list if d not in found_devs]
    if missing_devs:
        logger.error("="*60)
        logger.error(f"FATAL ERROR: Requested disks do not exist in VM: {missing_devs}")
        logger.error(f"Found disks: {found_devs}")
        logger.error("Check the --disk parameter")
        logger.error("="*60)
        return None

    return details

def check_clean_state(dom, disk_details):
    try:
        if dom.jobInfo()[0] != 0: return False, "Active Libvirt job detected (BlockCommit or Copy in progress)."
        if dom.snapshotNum(0) > 0: return False, "Registered snapshot detected (Not supported with external backup)."
    except: pass
    for dev, info in disk_details.items():
        if any(p in os.path.basename(info['path']) for p in FORBIDDEN_PATTERNS):
            return False, f"Disk '{dev}' appears to be a temporary or dirty snapshot."
    return True, "Clean"

def check_available_space(backup_dir, disk_details):
    # Calculate needed space (Current disk size + safety margin)
    needed = sum([os.path.getsize(i['path']) for i in disk_details.values()]) * (1 + SAFETY_MARGIN_PERCENT)
    os.makedirs(backup_dir, exist_ok=True)
    
    free_space = shutil.disk_usage(backup_dir).free
    if needed > free_space:
        logger.error(f"Insufficient space at destination. Needed: {needed/1024**3:.2f}GB | Free: {free_space/1024**3:.2f}GB")
        return False
    return True

# --- RETENTION MANAGEMENT ---
def manage_retention(backup_dir, days):
    if not os.path.isdir(backup_dir): return
    cutoff = datetime.now() - timedelta(days=days)
    backups = []
    
    try:
        # List all .bak backups
        for f in os.listdir(backup_dir):
            if f.endswith('.bak'):
                fp = os.path.join(backup_dir, f)
                mtime = os.path.getmtime(fp)
                dt = datetime.fromtimestamp(mtime)
                
                # Extract file identity to group (e.g. vm-vda)
                match = re.search(r"(.+)-(\d{8}_\d{6})", f)
                if match:
                    identity = match.group(1) # e.g. vm46176-vda
                    date_str = dt.strftime('%Y-%m-%d')
                    # Unique key: Date + Disk
                    unique_key = f"{date_str}_{identity}"
                else:
                    unique_key = f"{dt.strftime('%Y-%m-%d')}_{f}" # Fallback
                
                backups.append({'path': fp, 'dt': dt, 'unique_key': unique_key})
        
        # Sort: Newest first
        backups.sort(key=lambda x: x['dt'], reverse=True)
        
    except Exception as e: logger.error(f"Error listing backups for retention: {e}"); return

    if not backups:
        logger.info(f"--- RETENTION: No files found. ---")
        return

    keep_list = []
    delete_list = []
    seen_keys = set()

    # Apply rules
    for b in backups:
        if b['unique_key'] in seen_keys:
            delete_list.append((b, "Redundant from same day (Replaced by new one)"))
        else:
            seen_keys.add(b['unique_key'])
            if b['dt'] < cutoff:
                delete_list.append((b, "Expired (Older than retention limit)"))
            else:
                keep_list.append(b)

    # Safety Lock
    if not keep_list and delete_list:
        rescued, reason = delete_list.pop(0)
        keep_list.append(rescued)
        logger.warning(f"--- SAFETY LOCK: Keeping last available backup ({os.path.basename(rescued['path'])}) even if expired. ---")

    if sys.stdout.isatty(): print()
    logger.info(f"--- RETENTION ANALYSIS ({days} days) ---")
    
    if keep_list:
        logger.info("VALID (Kept):")
        for b in keep_list: logger.info(f"   [OK] {os.path.basename(b['path'])} ({b['dt'].strftime('%m/%d %H:%M')})")
            
    if delete_list:
        logger.info("CLEANUP (To be removed):")
        for b, reason in delete_list:
            logger.info(f"   [X] {os.path.basename(b['path'])}")
            logger.info(f"       Reason: {reason}")
            try: 
                os.remove(b['path'])
                logger.info("       -> Removed successfully.")
            except Exception as e:
                logger.error(f"       -> Failed to remove: {e}")
    
    logger.info("-" * 40)
    if sys.stdout.isatty(): print()

# --- MONITORING AND BACKUP ---

def monitor_global_progress(target_files, total_bytes_all_disks):
    spinner = "|/-\\"
    spin = spinner[int(time.time()*4)%4]
    
    current_bytes_total = 0
    for fp in target_files:
        try:
            if os.path.exists(fp): current_bytes_total += os.path.getsize(fp)
        except: pass
        
    perc = (current_bytes_total / total_bytes_all_disks * 100) if total_bytes_all_disks > 0 else 0
    
    # Calculate GB for cleaner display
    curr_gb = current_bytes_total / (1024**3)
    total_gb = total_bytes_all_disks / (1024**3)

    msg = f"INFO: [ALL DISKS] [{spin}] {curr_gb:.2f}GB / {total_gb:.2f}GB ({perc:.1f}%)"
    
    if sys.stdout.isatty():
        sys.stdout.write(f"\r\033[K{msg}")
        sys.stdout.flush()
    return msg

def run_atomic_backup(dom, backup_dir, disk_details, timestamp):
    global BACKUP_JOB_RUNNING, FILES_TO_CLEANUP
    
    logger.info("Starting ATOMIC backup (Parallel/Consistent)...")

    # 1. Prepare Paths and Calculate Totals
    disk_xml_fragments = []
    target_files_map = {} # dev -> path
    total_bytes_source = 0
    
    for dev, info in disk_details.items():
        fp = os.path.join(backup_dir, f"{dom.name()}-{dev}-{timestamp}.{DISK_FORMAT}.bak")
        target_files_map[dev] = fp
        FILES_TO_CLEANUP.append(fp) # Mark for cleanup
        
        # Build XML fragment for this disk
        disk_xml_fragments.append(
            f"<disk name='{dev}' type='file'><target file='{fp}'/><driver type='{DISK_FORMAT}'/></disk>"
        )
        
        total_bytes_source += os.path.getsize(info['path'])
        logger.info(f" -> Queued Disk '{dev}': {fp}")

    # 2. Construct Single Atomic XML
    full_xml = f"<domainbackup><disks>{''.join(disk_xml_fragments)}</disks></domainbackup>"
    
    logger.info(f"Total size to transfer: {total_bytes_source / (1024**3):.2f} GB")
    
    try:
        # 3. Start ONE Job for ALL disks
        logger.info("[Libvirt] Requesting atomic checkpoint...")
        dom.backupBegin(full_xml, None, 0)
        BACKUP_JOB_RUNNING = True
        logger.info("[Libvirt] Backup streams started.")
        
        last_log_time = 0
        target_files_list = list(target_files_map.values())

        while True:
            stats = dom.jobStats()
            if not stats or stats.get('type', 0) == 0:
                # Job Finished
                if sys.stdout.isatty(): print(f"\r\033[KINFO: [Success] Atomic Backup finished.")
                BACKUP_JOB_RUNNING = False
                break
            
            if stats.get('status') == libvirt.VIR_DOMAIN_JOB_FAILED:
                 raise Exception("Libvirt reported Job failure.")

            current_time = time.time()
            if sys.stdout.isatty():
                monitor_global_progress(target_files_list, total_bytes_source)
            elif current_time - last_log_time > 60:
                # Log progress periodically for non-interactive
                curr_size = sum([os.path.getsize(f) for f in target_files_list if os.path.exists(f)])
                logger.info(f"Progress: {curr_size}/{total_bytes_source} Bytes")
                last_log_time = current_time
            time.sleep(0.5)
            
    except Exception as e:
        logger.error(f"ERROR during atomic backup: {e}")
        perform_cleanup() 
        raise 
    
    # Success: Clear cleanup list
    for fp in target_files_map.values():
        if fp in FILES_TO_CLEANUP: FILES_TO_CLEANUP.remove(fp)

    logger.info("Atomic backup completed successfully!")

# --- MAIN ---
if __name__ == "__main__":
    
    parser = argparse.ArgumentParser(description="Atomic Live KVM Backup (Libvirt API) - CLI")
    
    parser.add_argument('--domain', required=True, help="VM Name (e.g., vm46176)")
    parser.add_argument('--backup-dir', required=True, help="Base destination directory")
    parser.add_argument('--disk', required=True, nargs='+', help="List of disks to backup (e.g., vda vdb)")
    parser.add_argument('--retention-days', type=int, required=False, default=7, help="Retention days (Default: 7)")
    
    args = parser.parse_args()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    setup_logging(args.domain, timestamp)
    
    conn = None
    try:
        conn = libvirt.open(CONNECT_URI)
        try:
            dom = conn.lookupByName(args.domain)
        except libvirt.libvirtError:
            logger.error(f"VM '{args.domain}' not found in hypervisor.")
            sys.exit(1)
            
        CURRENT_DOMAIN_NAME = args.domain 

        try: 
            if dom.jobInfo()[0] != 0: 
                logger.warning("Previous job detected. Attempting to abort...")
                subprocess.run(['virsh', 'domjobabort', args.domain], stderr=subprocess.DEVNULL)
        except: pass

        bkp_dir = os.path.join(args.backup_dir, args.domain)
        
        details = get_disk_details_from_xml(dom, args.disk)
        if not details: raise Exception("Requested disks not found.")
        
        clean, msg = check_clean_state(dom, details)
        if not clean:
            logger.error(f"\nABORTED: {msg}\nThe VM must be clean (no active snapshots/jobs) for backup.")
            sys.exit(1)
            
        if not check_available_space(bkp_dir, details): 
            sys.exit(1)
        
        # 1. EXECUTE ATOMIC BACKUP (All disks at once)
        run_atomic_backup(dom, bkp_dir, details, timestamp)

        # 2. EXECUTE RETENTION
        logger.info("Starting retention check and cleanup...")
        manage_retention(bkp_dir, args.retention_days)
        
        logger.info("PROCEDURE FINISHED SUCCESSFULLY.")
        
    except Exception as e:
        logger.exception(f"FATAL ERROR: {e}")
        sys.exit(1)
    finally: 
        if conn: conn.close()